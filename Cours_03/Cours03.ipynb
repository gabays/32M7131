{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gabays/32M7131/blob/main/Cours_03/Cours03.ipynb)\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Licence Creative Commons\" style=\"border-width:0;float:right;\\\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a>\n",
        "\n",
        "Distant Reading 2: linguistique computationnelle\n",
        "\n",
        "# **Lemmatiser un texte**\n",
        "\n",
        "Simon Gabay\n",
        "\n",
        "\n",
        "\n",
        "üö® Pour les entra√Ænements, on va avoir besoin d'un GPU √† notre meilleur ami Google: vous pouvez en demander en allant sur dans le menu en haut √† gauche et en choisissant `Execution` > `Modifier le type d'ex√©cution` puis en choisissant `GPU`.\n",
        "\n",
        "‚ö†Ô∏è <font color='red'>Attention! l'usage des GPU est limit√©!!!! Il faut les utiliser avec parcimonie, sinon il faut payer!! Ou bien vous pouvez tout faire en ligne de commande sur les clusters HPC de l'uni.</font> Pour rappel, une documentation est disponible [ici](https://github.com/FoNDUE-HTR/Documentation/blob/master/CLUSTERS.md), mais concerne l'entra√Ænement de mod√®les d'OCR.\n",
        "\n"
      ],
      "metadata": {
        "id": "YQAm1X2uzJHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Annoter\n",
        "\n",
        "### 1.1 Premier test\n",
        "\n",
        "Il nous faut d'abord installer [_pie-extended_](https://pypi.org/project/pie-extended/) pour utiliser le lemmatiseur [_Pie_](https://github.com/emanjavacas/pie). Il existe bien d'autres outils: l'un des plus populaires est [_spaCy_](https://spacy.io), qui couvre les principales langues (allemand, fran√ßais, anglais, espagnol, anglais‚Ä¶), mais nous nous int√©ressons √† des langues moins bien dot√©es et d'une nature diff√©rente (pr√©-orthographiques) qui n√©cessitent des solutions sp√©cifiques."
      ],
      "metadata": {
        "id": "AGw9TcXHhnil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxn4vDYUyzLA"
      },
      "outputs": [],
      "source": [
        "!pip install pie-extended"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous t√©l√©chargeons les mod√®les pour le fran√ßais (dit `fr`) -- une liste des mod√®les disponibles est [en ligne](https://pypi.org/project/pie-extended)."
      ],
      "metadata": {
        "id": "q18vBoCG1Hf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie-extended download fr"
      ],
      "metadata": {
        "id": "Pe7aPaOx0PXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous cr√©ons un fichier `essai.txt` un avec la phrase _je m'appelle Simon_:"
      ],
      "metadata": {
        "id": "vb0cpYyzcfOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"je m'appelle Simon\" >> essai.txt"
      ],
      "metadata": {
        "id": "T9FxB_S40awP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec `pie extended` j'annote (`tag`) avec le mod√®le `fr`:"
      ],
      "metadata": {
        "id": "Rm9WiW_acsuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie-extended tag fr /content/essai.txt"
      ],
      "metadata": {
        "id": "Tfc5lld71XiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il me cr√©e automatiquement un fichier du m√™me nom en ajoutant `-pie` au nom avant l'extension. Je peux regarder le r√©sultat en ouvrant le fichier avec la commande bash `cat`:"
      ],
      "metadata": {
        "id": "vhxFlfn1dDmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/essai-pie.txt"
      ],
      "metadata": {
        "id": "9kYaUBrj2gk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Un test plus ambitieux\n",
        "\n",
        "Nous recommen√ßons avec un texte plus complexe: la premi√®re fable de _L‚Äô√âcole des femmes_ de Moli√®re [disponible sur wikisource]([Wikisource](https://fr.wikisource.org/wiki/L%E2%80%99%C3%89cole_des_femmes/%C3%89dition_Chasles,_1888):"
      ],
      "metadata": {
        "id": "AJsOdi6PhsLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/gabays/32M7131/master/Cours_03/docs/moliere.txt > /content/moliere.txt\n",
        "!head -10 /content/moliere.txt"
      ],
      "metadata": {
        "id": "otX2BLgAeNir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'annote ce fichier:"
      ],
      "metadata": {
        "id": "eLn2jWsTOje9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie-extended tag fr /content/moliere.txt\n",
        "!head -10 /content/moliere-pie.txt"
      ],
      "metadata": {
        "id": "zY9o1TUfe3_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Un essai en latin\n",
        " Recommen√ßons avec un texte en latin. Il faut d'abord charger le mod√®le latin et les _addons_"
      ],
      "metadata": {
        "id": "avQc5QIzeujG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie-extended download lasla\n",
        "!pie-extended install-addons lasla"
      ],
      "metadata": {
        "id": "4fNui7BSln5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "T√©l√©chargeons d√©sormais un texte, le _Pro Quinctio_ de Cic√©ron disponible sur [_The Latin Library_](https://www.thelatinlibrary.com/cicero/quinc.shtml)."
      ],
      "metadata": {
        "id": "2RHmzoutlz9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/gabays/32M7131/master/Cours_03/docs/Cicero_%20Pro_Quinctio.txt > /content/Cicero_%20Pro_Quinctio.txt\n",
        "!head -10 /content/Cicero_%20Pro_Quinctio.txt"
      ],
      "metadata": {
        "id": "BPBi_8TNlzkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On annote et on observe le r√©sultat:"
      ],
      "metadata": {
        "id": "OuD9dfxmJb18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie-extended tag lasla /content/Cicero_%20Pro_Quinctio.txt\n",
        "!head -10 /content/Cicero_%20Pro_Quinctio-pie.txt"
      ],
      "metadata": {
        "id": "6OEL6lIJmrVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Entra√Æner un mod√®le\n",
        "### 2.1 _Split_ pour l'entra√Ænement\n",
        "\n",
        "Nous allons d'abord faire un _split_ et cr√©er les trois jeux de donn√©es n√©cessaires avec [_Protogenie_](https://github.com/hipster-philology/protogenie).\n",
        "\n",
        "R√©cup√©rons d'abord un jeu de donn√©es."
      ],
      "metadata": {
        "id": "3bwOZivysc5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/gabays/32M7131/main/Cours_03/train/lemma_Empty.txt > /content/lemma_Empty.txt\n",
        "!head -20 /content/lemma_Empty.txt"
      ],
      "metadata": {
        "id": "x9wG8KKIs2so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite nous installons _Protogenie_."
      ],
      "metadata": {
        "id": "VZQ6FN0zt1cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protogenie"
      ],
      "metadata": {
        "id": "VB1QLtCUt4Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On charge un fichier de config (pour apprendre √† les fabriquer, il existe une [documentation](https://github.com/hipster-philology/protogenie/blob/master/DOCUMENTATION.md)).\n",
        "\n"
      ],
      "metadata": {
        "id": "s9SGk4-Et9Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/gabays/32M7131/main/Cours_03/train/lemma_Empty.xml > /content/lemma_Empty.xml\n",
        "!cat /content/lemma_Empty.xml"
      ],
      "metadata": {
        "id": "EYBcNPBQuJe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On fait le split -- ici 10% en `dev`, 10% en `eval` (ou `test`) et 80% en `train`, mais cette r√©partition peut changer en fonction de la quantit√© de donn√©es dont on dispose."
      ],
      "metadata": {
        "id": "H3aZBlmfuNy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!protogenie build /content/lemma_Empty.xml -d 0.1 -e 0.1 -t 0.8"
      ],
      "metadata": {
        "id": "1Lbf38U-1XIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Entrainement\n",
        "On va entra√Æner avec [_Pie_](https://github.com/emanjavacas/pie)."
      ],
      "metadata": {
        "id": "y2mJAStU2sih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlp-pie"
      ],
      "metadata": {
        "id": "saEY2pqf3FF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a besoin de renommer les fichiers cr√©√©s avec _Protog√©nie_ en `.tsv`"
      ],
      "metadata": {
        "id": "CRqa1P3IAfA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/output/dev/lemma_Empty.txt /content/output/dev/lemma_Empty.tsv\n",
        "!mv /content/output/test/lemma_Empty.txt /content/output/test/lemma_Empty.tsv\n",
        "!mv /content/output/train/lemma_Empty.txt /content/output/train/lemma_Empty.tsv"
      ],
      "metadata": {
        "id": "9SGEWJ-e4I6J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons aussi besoin d'un fichier de configuration"
      ],
      "metadata": {
        "id": "y9Gxq65l6Buy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/gabays/32M7131/main/Cours_03/train/config.json > /content/config.json\n",
        "!cat /content/config.json"
      ],
      "metadata": {
        "id": "Xqm6DFu06Fig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce fichier contient toutes les informations n√©cessaires pour l'entra√Ænement. Le param√©trage via le fichier de configuration est extr√™mement complexe, et il est difficile (impossible?) de conna√Ætre √† l'avance les meilleurs choix √† op√©rer: il faut souvent faire de nombreux tests.\n",
        "\n",
        "Si vous voulez un peu comprendre le contenu, voici quelques explications:\n",
        "```json\n",
        "{\n",
        "  // * General\n",
        "  // model name to be used for saving\n",
        "  \"modelname\": \"latest-fro\",\n",
        "  // model path to be used for saving\n",
        "  \"modelpath\": \"./\",\n",
        "  // run test (no serialization)\n",
        "  \"run_test\": false,\n",
        "  // max length of sentences (longer sentence will be split)\n",
        "  \"max_sent_len\": 35,\n",
        "  // maximum number of sentences to process\n",
        "  \"max_sents\": 1000000,\n",
        "  // * Data\n",
        "  // path or unix-like expression to file(s)/dir with training data:\n",
        "  // e.g. \"datasets/capitula_classic/train0.tsv\"\"\n",
        "  \"input_path\": \"corpus_for_train/train/CORPUS.tsv\",\n",
        "  // path to test set (same format as input_path)\n",
        "  \"test_path\": \"corpus_for_train/test/CORPUS.tsv\",\n",
        "  // path to dev set (same format as input_path)\n",
        "  \"dev_path\": \"corpus_for_train/dev/CORPUS.tsv\",\n",
        "  // data to use as reference for breaking lines (e.g. \"pos\")\n",
        "  \"breakline_ref\": \"POS\",\n",
        "  // needed to decide for a sentence boundary (e.g. \"$.\")\n",
        "  \"breakline_data\": \"INUTILE\",\n",
        "  // maximum vocabulary size\n",
        "  \"char_max_size\": 500,\n",
        "  // maximum vocabulary size for word input\n",
        "  \"word_max_size\": 20000,\n",
        "  // min freq per item to be incorporated in the vocabulary (only used if *_max_size is 0)\n",
        "  \"char_min_freq\": 1,\n",
        "  \"word_min_freq\": 1,\n",
        "  // char-level encoding\n",
        "  \"char_eos\": true,\n",
        "  \"char_bos\": true,\n",
        "  // tab-format only:\n",
        "  \"header\": true,\n",
        "  // separator for csv-like files\n",
        "  \"sep\": \"\\t\",\n",
        "  // task-related config\n",
        "  \"tasks\": [\n",
        "    // each task's name refers to the corresponding data field\n",
        "    // this behaviour can be changed in case the name differs from the data field\n",
        "    // by using a \"target\" key that refers to the target data field\n",
        "    // e.g. {\"name\": \"lemma-char\", \"settings\": {\"target\": \"lemma\"}}\n",
        "    // e.g. {\"name\": \"lemma-word\", \"settings\": {\"target\": \"lemma\"}}\n",
        "    {\n",
        "      \"name\": \"lemma\",\n",
        "      \"target\": true,\n",
        "      \"context\": \"sentence\",\n",
        "      \"level\": \"char\",\n",
        "      \"decoder\": \"attentional\",\n",
        "      \"settings\": {\n",
        "        \"bos\": true,\n",
        "        \"eos\": true,\n",
        "        \"lower\": true,\n",
        "        \"target\": \"lemma\"\n",
        "      },\n",
        "      \"layer\": -1\n",
        "    },\n",
        "    {\"name\": \"POS\"}\n",
        "  ],\n",
        "  \"task_defaults\": {\n",
        "    \"level\": \"token\",\n",
        "    \"layer\": -1,\n",
        "    \"decoder\": \"linear\",\n",
        "    \"context\": \"sentence\"\n",
        "  },\n",
        "  // general task schedule params (can be overwritten in the \"settings\" entry of each)\n",
        "  \"patience\": 1000000, // default to very large value\n",
        "  \"factor\": 1, // decrease the loss weight by this amount (0, 1)\n",
        "  \"threshold\": 0, // minimum decrease in loss to be considered an improvement\n",
        "  \"min_weight\": 0, // minimum value a task weight can be decreased to\n",
        "\n",
        "  // whether to include autoregressive loss\n",
        "  \"include_lm\": true,\n",
        "  // whether to share the output layer for both fwd and bwd lm\n",
        "  \"lm_shared_softmax\": false,\n",
        "  // lm settings in case it's included as an extra task\n",
        "  \"lm_schedule\": {\n",
        "    \"patience\": 100, \"factor\": 0.5, \"weight\": 0.2, \"mode\": \"min\"\n",
        "  }\n",
        "}\n",
        "  ```\n",
        "\n"
      ],
      "metadata": {
        "id": "bJzaEqNjB9Fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et on entraine. Le nombre d'it√©rations (_epochs_) est volontairement limit√© √† 10 pour ne pas gaspiller trop d'√©nergie inutilement. En augmentant ce nombre, on obtiendrait un bien meilleur r√©sultat.\n",
        "\n",
        "Vous allez voir appara√Ætre les scores sur le `dev` our chaque it√©ration. Pour lire les r√©sultats, [cf. pr√©cision et rappel sur wikipedia](https://fr.wikipedia.org/wiki/Pr%C3%A9cision_et_rappel)."
      ],
      "metadata": {
        "id": "wWO-357V6Wdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pie train config.json"
      ],
      "metadata": {
        "id": "NVNetesS6g4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut d√©sormais utiliser ce mod√®le avec _Pie_:\n"
      ],
      "metadata": {
        "id": "OW0AXvF-QudR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pie tag /content/mymodel.tar /content/moliere.txt"
      ],
      "metadata": {
        "id": "p0Oj_fEwQ28V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention, _Pie_ n'est pas _Pie extended_. Pour ajouter le mod√®le √† ce dernier vous pouvez suivre [le tuto](https://github.com/hipster-philology/nlp-pie-taggers#add-a-model).\n",
        "\n",
        "Il faut d√©sormais un mod√®le pour la POS ‚Äì mais vous avez d√©sormais les armes pour le faire vous-m√™me."
      ],
      "metadata": {
        "id": "TUvBwgTtHVqD"
      }
    }
  ]
}